---
title: "Week 8: Spam"
layout: post
draft: true
---

Week 8: Spam
============

This week was titled "messaging security",
but it is actually all about spam detection.


Blocking spam
---

RBL - realtime blackhole list


Detecting spam
----


Methods:
- rule-based
- bayesian


### Rule-based


### Bayesian

I already did a rule-based approach for URL classification last week,
so I figured I'd try the Bayesian approach this time.

I believe the Bayesian approach to spam filtering was first described by
Paul Graham in [A Plan for Spam][], an essay published in August 2002.

[A Plan for Spam]: http://www.paulgraham.com/spam.html

This became the [SpamBayes][] project, an open-source Python program
that used Bayesian filtering to flag spam. It enjoyed a few year of
success, but it is now unmaintained. Its last release was in 2008.

[SpamBayes]: https://en.wikipedia.org/wiki/SpamBayes


Nowadays, though, spammers have gotten more sophisticated and the best filters
are run by large corporations like Google who can use a huge database of spam
messages to train more sophisticated machine learning modules.

[google]: https://gmail.googleblog.com/2015/07/the-mail-you-want-not-spam-you-dont.html

Just like last time, it is more important to have few false positives
than to catch all spam messages. However, note that because of the volume of spam
- several billion spam messages are sent every day [source?] -
if your spam filter is 99% accurate then that 1% represents 10 million spam messages
that get through.


In which I ignore the lesson plan and do something else
----


We were supposed to come up with some home-grown rules for flagging spam messages,
but since I already basically did that last week,
I decided to try the Bayesian approach.


We are interested in computing:

    P(spam | word)

This is read as "the probability that a message is spam, given that it contains
the word _word_".

Per Bayes' Theorem,
    
    P(spam | word)  = P(word | spam) / P(spam)

Where P(word | spam) is the probability that a word appears in a spam message,
and P(spam) is just the overall probability that a message is spam.

(P(spam) represents our *prior probability* that we believe the message is spam,
and P(spam|word) is the *posterior probability* after observing that it contains
word. 

We'll assume P(spam) is .5 even though the actual distribution is closer .85,
to avoid biasing the algorithm towards classifying messages as spam.)


[code here]

By training my bayesian filter on the full database of 100,000 messages,
i was able to flag messages correctly expcept for 493 cases [double check],
which is an accuracy rate of more than 99.5%

[picture of 493 here]

This, of course, is cheating, because you aren't allowed to verify your
algorithm on the same data set you used to train it.

So let's try again.

If i train on a random sample of 50,000 messages, the accuracy goes down.
This time i misclassified 4,441 message, which is only 95.5% accurate.


Also of note: i did absolutely nothing to try and minimize false positives.



In the recorded lectures, the class divided into three groups to try and
classify the spam messages.

I want to repeat some of their methods here.

- The first group got a large number of messages by flagging messages
  with the subject "Low Stock Prices [TODO]", and then _looking at which IPs
  sent those messages and blocking all messages from those IPs_.

  In effect, they created a post-hoc IP blackhole list.

    [image of Stock Prices subjects]

- Another group used the attachment hash.


- The third group did[something].




Acknowledgements
---

This post is based on lecures given by
So and So.
